name: Fetch updated data and deploy

on:
  push:
#  schedule:
#    - cron: '5,35 * * * *'

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Check out repo
      uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v1
      with:
        python-version: 3.8
    - uses: actions/cache@v1
      name: Configure pip caching
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Download all .db files
      env:
        DATASETTE_TOKEN: ${{ secrets.DATASETTE_TOKEN }}
      run: |-
        curl -s -H "Authorization: Bearer $DATASETTE_TOKEN" https://biglocal.datasettes.com/-/databases.json | jq '.[].path' -r | while read path;
          do curl -s -H "Authorization: Bearer $DATASETTE_TOKEN" https://biglocal.datasettes.com/$path -o $path
        done;
    - name: Fetch projects
      env:
        BIGLOCAL_TOKEN: ${{ secrets.BIGLOCAL_TOKEN }}
      run: python fetch_projects.py $BIGLOCAL_TOKEN
    - name: Populate tables
      run: python populate_tables.py
    - name: Set variables to decide if we should deploy
      id: decide_variables
      env:
        DATASETTE_TOKEN: ${{ secrets.DATASETTE_TOKEN }}
      run: |-
        echo "##[set-output name=latest_db_hash;]$(md5sum -b *.db | md5sum | cut -f 1 -d ' ')"
        echo "##[set-output name=deployed_db_hash;]$(curl -s -H "Authorization: Bearer $DATASETTE_TOKEN" https://biglocal.datasettes.com/-/versions.json | jq '.datasette.note' -r)"
    - name: Set up Cloud Run
      uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
      if: github.event_name == 'push' || steps.decide_variables.outputs.latest_db_hash != steps.decide_variables.outputs.deployed_db_hash
      with:
        version: '275.0.0'
        service_account_email: ${{ secrets.GCP_SA_EMAIL }}
        service_account_key: ${{ secrets.GCP_SA_KEY }}
    - name: Deploy to Cloud Run
      if: github.event_name == 'push' || steps.decide_variables.outputs.latest_db_hash != steps.decide_variables.outputs.deployed_db_hash
      env:
        DATASETTE_TOKEN: ${{ secrets.DATASETTE_TOKEN }}
        GH_CLIENT_ID: ${{ secrets.GH_CLIENT_ID }}
        GH_CLIENT_SECRET: ${{ secrets.GH_CLIENT_SECRET }}
      run: |-
        gcloud config set run/region us-central1
        gcloud config set project datasette-222320
        datasette publish cloudrun *.db \
           --service=biglocal \
           --install=datasette-auth-github \
           --plugin-secret datasette-auth-github client_id $GH_CLIENT_ID \
           --plugin-secret datasette-auth-github client_secret $GH_CLIENT_SECRET \
           --plugin-secret datasette-auth-github allow_org biglocalnews \
           --plugin-secret token-auth secret $DATASETTE_TOKEN \
           --memory=2Gi \
           --plugins-dir=plugins \
           -m metadata.json \
           --version-note="$(md5sum -b *.db | md5sum | cut -f 1 -d ' ')"
